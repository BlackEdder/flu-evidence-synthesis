---
title: "Using fluEvidenceSynthesis to infer epidemological parameters."
author: "Edwin van Leeuwen"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parameter inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r,include=F}
library(pander)
```

# Introduction

This package implements all the tools needed to analyse and compare the effectiveness of different Influenza vaccine programs (see Baguelin et al. (2013) for more details). This analysis has two main steps.

#. Parameter inference using existing model
#. Simulation of different possible vaccination strategies using the inferred parameters

This vignette will focus on how the fluEvidenceSythesis package can be used to perform the first step of parameter inference.

The method we use here combines data from numerous sources that are then used to compute the likelihood of the predicted number of influenza cases in a given week. Given the data and the likelihood function we use MCMC to obtain the posterior distribution of the parameters of an underlying epidemiological model. In this vignette we give practical examples on the required data and how to use the package to perform the MCMC fitting.

The epidemiological model is a compartmental model with Susceptible, Exposed, Infection and Recovered (SEIR) compartments. Waiting time between Exposed and Infectious and between Infectious and Recovered are assumed to be gamma distributed. The epidemiological parameters used in the model are the transmissibility, susceptibility, time latent (time between exposed and susceptible) and the time infectious. Further details of the underlying model and techniques can be found in Baguelin et al. (2013). 

The methods are computationally intensive and fitting the model can easily take a couple of hours on a powerfull machine. For example an inference run of 11 million samples (1 million burn in) will take about 8-9 hours on a relatively modern machine (2015, Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz). Of course one can run different years/strains in parallell.

# Examples

## Simple example

The example below shows an example for the case where the data used corresponds to the structure of the data gathered in the UK. The example assumes 7 age groups: <1, 1-4, 5-14, 15-24, 25-44, 45-64, >65. In the UK ILI and virulogical data are only separated into 5 age groups though (<4,5-14,15-24,25-64,>65), so `inference` will internally group the first two (<1,1-4) and the middle age groups together when calculating the likelihood of the model given the data.

This example first loads the data and then runs the inference function which returns the results of parameter inference using MCMC. This option is the most performant one, since everything is implemented in C++, but also the least flexible option.

```{r,cache=T}
library(fluEvidenceSynthesis)
data("age_sizes")
data("vaccine_calendar")
data("polymod_uk")
data("ili")
data("confirmed.samples")

initial.parameters <- c(0.01188150, 0.01831852, 0.05434378,
                        1.049317e-05, 0.1657944,
                        0.3855279, 0.9269811, 0.5710709,
                        -0.1543508 )

inference.results <- inference( age_sizes=age_sizes$V1,
                      vaccine_calendar=vaccine_calendar,
                      polymod_data=as.matrix(polymod_uk),
                      ili=ili$ili,
                      mon_pop=ili$total.monitored,
                      n_pos=confirmed.samples$positive,
                      n_samples=confirmed.samples$total.samples,
                      initial = initial.parameters,
                      nbatch=1000,
                      nburn=1000, blen=10 )
```

The data used for the inference is:

age_sizes
  ~ Vector of population sizes of a certain age. First element is everyone below 1, second every below 2 etc. The final entry will be interpreted as everyone of that age or higher (needs to be higher than 65).
  
vaccine_calendar
  ~ Object representing the vaccine program applied that year. In short this contains the fraction of population, in a certain age and risk group, vaccinated within a given week.
  
polymod_data
  ~ Data gathered by the POLYMOD study on contacts of subjects with the different age groups. This data will be resampled during inference to use as a prior distribution on contacts.
 
ili
  ~ The number of people with Influenza Like Illness in each week

mon_pop
  ~ The total number of people monitored for ILI. For the UK this is defined as the number of people registered at the General Practitioner (GP; Doctor).
  
n_pos
  ~ The number of samples positive for a given Influenza strain
  
n_samples
  ~ The number of total samples tested. This is assumed to be a strict subset of the number of ILI cases
  
  
The `inference` function returns a list with the accepted parameters (`inference.results$batch`) and the corresponding log-likelihood values (`inference.results$llikelihoods`) as well as a matrix (`inference.results$contact.ids`) containing the row numbers of the contacts data used to build the contact matrix.

```{r}
pander(head(inference.results$batch))
```

Each row represents a sample of posterior parameter values. The order of the parameters is as follows:

- 1-3: Ascertainment probabilty for three age groups ($\epsilon_i$)
- 4: Outside infection ($\psi$)
- 5: Transmissibility ($q$)
- 6-8: Susceptibility for three age groups ($\sigma_i$)
- 9: Initial number of infections ($I$)
  
For more details on the input data see `?data_name`, e.g. `?polymod_uk` will give an overview of the polymod data layout required.
  
## More in depth example

Above we used the general `inference` function to perform parameter inference using the data. In this section we implement this function in R, which allows adjustment of the inference process to allow different data structures or different number of age groups. This method gives the user more control, but it will be slower than calling the `inference` function directly.

To perform parameter inference we first need to define a function that returns the (log) likelihood for given parameter values, as dependent on the data and a function which returns the log prior probability of the parameters. These functions are then passed to `adaptive.mcmc` which returns a posterior sample for the parameter values. By combining a number of data sources, the likelihood function becomes relatively complex, and so needs to perform the following steps (for full details see Baguelin et al., 2013):

- Bootstrap the POLYMOD data
- Run the model given the parameters
    - Note that we model 7 separate age groups, divided into low risk, high risk and pregnant women
- Convert the model results from 7 age groups to 5 age to match the structure of the ILI and confirmation data (which is subdivided into 5 age groups)
- Calculate the likelihood of the converted model results given the ILI and confirmation data

```{r,cache=T}
library(fluEvidenceSynthesis)

# This is to keep track of the bootstrapped contact results
current.contact.ids <- seq(1,nrow(polymod_uk))

# Load the data and return the log likelihood function given the data
build.llikelihood <- function()
{
  # Load all the data
  data("age_sizes")
  data("vaccine_calendar")
  data("polymod_uk")
  #data("mcmcsample")
  data("ili")
  data("confirmed.samples")
  
  # Sum all populations with a certain age into their corresponding age group
  age.group.sizes.5 <- separate.into.age.groups(age_sizes$V1,c(5,15,45,65))
 
  # Define the actual log likelihood function
  llikelihood.f <- function( pars )
  {
    # Resample contact ids. This is actually not ideal, because we should not accept
    # the resampling if new pars are not accepted
    # Possible solution: a parameter that (rounded) represents the number of steps from start. 
    if (runif(1,0,1)<0.1) {
      rs <- round(runif(2,1,length(current.contact.ids)))
      current.contact.ids[rs[1]] <- rs[2]
    }

    age.group.limits <- c(1,5,15,25,45,65)
    contacts <- contact.matrix(as.matrix(polymod_uk[current.contact.ids,]),
                               age_sizes[,1], age.group.limits )

    age.groups <- separate.into.age.groups( age_sizes[,1], 
                                           age.group.limits )

    # Fraction of each age group classified as high risk
    # We can classify a third risk group, but we are not doing
    # that here (the second row is 0 in our risk.ratios matrix)
    risk.ratios <- matrix(c(
                             0.021, 0.055, 0.098, 0.087, 0.092, 0.183, 0.45, 
                             0, 0, 0, 0, 0, 0, 0                          
                             ), ncol = 7, byrow = T)

    # Population sizes in each age and risk group
    popv <- separate.into.risk.groups(
                     age.groups, risk.ratios );

    # Population size initially infected by age and risk group
    initial.infected <- rep( 10^pars[9], 7 )
    initial.infected <- separate.into.risk.groups(
                                                  initial.infected, risk.ratios );

    # Run simulation
    # Note that to reduce complexity 
    # we are using the same susceptibility parameter for multiple age groups
    odes <- infectionODEs( popv, initial.infected,
                          vaccine_calendar,
                          contacts,
                          c(pars[6], pars[6], pars[6],
                            pars[7], pars[7], pars[7], pars[8]),
                          transmissibility = pars[5],
                          c(0.8,1.8), 7 )
    
    # Ignore times row
    odes <- odes[,2:22]
    
    # Convert the 7 age groups for each risk group to 5 groups
    converted.odes <- odes
    converted.odes[,1] <- rowSums(odes[,c(1,2,8,9,15,16)])
    converted.odes[,2] <- rowSums(odes[,c(3,10,17)])
    converted.odes[,3] <- rowSums(odes[,c(4,5,11,12,18,19)])
    converted.odes[,4] <- rowSums(odes[,c(6,13,20)])
    converted.odes[,5] <- rowSums(odes[,c(7,14,21)])
    converted.odes <- converted.odes[,1:5]
    
    # For each week and each group sum log likelihood
    epsilons <- c(pars[1], pars[1], pars[2], pars[2], pars[3])
    ll <- log_likelihood_cases(
            epsilons,pars[4], as.matrix(converted.odes),
            age.group.sizes.5, ili$ili, ili$total.monitored,
            confirmed.samples$positive, confirmed.samples$total.samples )
    return(ll)
  }
  return(llikelihood.f)
}

llprior <- function(pars) {
  if (any(pars[1:8] < 0) || any(pars[1:4] > 1) || any(pars[6:8] > 1)
      || pars[9] < log(0.00001) || pars[9] > log(10) )
    return(-Inf)
  
  lprob <- dnorm(pars[5], 0.1653183, 0.02773053, 1)
  lprob <- lprob + dlnorm(pars[1], -4.493789, 0.2860455, 1)
  lprob <- lprob + dlnorm(pars[2], -4.117028, 0.4751615, 1)
  lprob <- lprob + dlnorm(pars[3], -2.977965, 1.331832, 1)
  
  return(lprob)
}

init.pars <- c(0.01188150,0.01831852, 0.05434378, 1.049317e-05, 0.1657944,
                       0.3855279, 0.9269811, 0.5710709, -0.1543508)
llikelihood <- build.llikelihood()

# Run adaptive.mcmc
mcmc.result <- adaptive.mcmc(lprior = llprior, llikelihood = llikelihood, 
               outfun = function(pars) { current.contact.ids },
               nburn = 100, 
               initial = init.pars,
               nbatch = 100, blen = 10)
```

# Analysing the results

Plotting the resulting posterior parameter values^[Be aware that these results are for a very short mcmc run and are not realistic].

```{r,cache=T,fig.width=5,fig.height=5}
library(reshape2)
library(ggplot2)
colnames(inference.results$batch) <- c("eps1", "eps2", "eps3", "psi", "q",
                                       "susc1", "susc2", "susc3", "I0")

ggplot(data=melt(inference.results$batch)) + facet_wrap( ~ Var2, ncol=3, scales="free" ) + geom_histogram(aes(x=value,factor=Var2), bins=25)

```


## Posterior model results

Here we plot the credibility intervals of our models. Each plot is the result for one of the seven age groups and shows the number of new cases each week.

```{r,cache=T, fig.width=5, fig.height=5}
library(fluEvidenceSynthesis)
library(ggplot2)

# Function that runs the model given a set of parameters. Most of the function
# has todo with loading the correct inputs for the ODE model
ode.results <- function( pars ) 
{
  data("age_sizes")
  
  age.group.limits <- c(1,5,15,25,45,65)
  contacts <- contact.matrix(as.matrix(polymod_uk),
                             age_sizes[,1], age.group.limits )
  
  age.groups <- separate.into.age.groups( age_sizes[,1], 
                                          age.group.limits )
  
  # Fraction of each age group classified as high risk
  # We can classify a third risk group, but we are not doing
  # that here (the second row is 0 in our risk.ratios matrix)
  risk.ratios <- matrix( c(
    0.021, 0.055, 0.098, 0.087, 0.092, 0.183, 0.45, 
    0, 0, 0, 0, 0, 0, 0                          
  ), ncol=7, byrow=T )
  
  # Population sizes in each age and risk group
  popv <- separate.into.risk.groups(
    age.groups, risk.ratios );
  
  # Population size initially infected by age and risk group
  initial.infected <- rep( 10^pars[9], 7 )
  initial.infected <- separate.into.risk.groups(
    initial.infected, risk.ratios );
  
  # Run simulation
  # Note that to reduce complexity 
  # we are using the same susceptibility parameter for multiple age groups
  odes <- infectionODEs( popv, initial.infected,
                         vaccine_calendar,
                         contacts,
                         c(pars[6],pars[6],pars[6],
                           pars[7],pars[7],pars[7],pars[8]),
                         transmissibility=pars[5],
                         c(0.8,1.8), 7 )
  
  # For simplicity we sum the low and high risk group
  simplify.odes <- odes[,2:8]+odes[,9:15]+odes[,16:22]
  rownames(simplify.odes) <- odes[,1]
  return( simplify.odes )
}

# Calculate the credibility intervals for each time point. By default the function
# calculate it for the (equal tailed) credibility interval of 0% (median), 50% and 98%
cim <- credible.interval.model(ode.results, inference.results$batch, intervals=c(0,0.5, 0.98))
cim$row.ID <- as.Date(as.character(cim$row.ID)) 

ggplot( data=cim ) + facet_wrap( ~ column.ID, ncol=3, scales="free" ) +
  stat_ci( aes(row.ID,value,ci=aggregate, factor=column.ID) ) +
  xlab("Time") + ylab("New infections")
```

# References

Baguelin, Marc, Stefan Flasche, Anton Camacho, Nikolaos Demiris, Elizabeth Miller, and W. John Edmunds. ‘Assessing Optimal Target Populations for Influenza Vaccination Programmes: An Evidence Synthesis and Modelling Study.’ PLoS Med 10, no. 10 (2013): e1001527. doi:10.1371/journal.pmed.1001527.
